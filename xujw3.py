import asyncio
import aiohttp
import re
import yaml
import os
import base64
import ipaddress
from urllib.parse import quote, urlparse
from tqdm import tqdm
from loguru import logger
import json

# å…¨å±€é…ç½® (ä¿æŒä¸å˜)
RE_URL = r"https?://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]"
CHECK_NODE_URL_STR = "https://{}/sub?target={}&url={}&insert=false&config=config%2FACL4SSR.ini"
CHECK_URL_LIST = ['api.dler.io', 'sub.xeton.dev', 'sub.id9.cc', 'sub.maoxiongnet.com']
MIN_GB_AVAILABLE = 5 # æœ€å°å¯ç”¨æµé‡ï¼Œå•ä½ GB

# -------------------------------
# èŠ‚ç‚¹è¿‡æ»¤åŠŸèƒ½
# -------------------------------
def is_ip_address(server: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºIPåœ°å€"""
    try:
        ipaddress.ip_address(server.strip('[]'))
        return True
    except Exception:
        return False

def is_cloudflare_http_node(node_url: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºCloudflare http/httpsç«¯å£èŠ‚ç‚¹"""
    try:
        parsed = urlparse(node_url)
        server = parsed.hostname or ''
        port = parsed.port or 443
        
        # Cloudflare åŸŸåå¸¸è§å†™æ³•
        cf_keywords = ["cloudflare.com", ".cloudflare-"]
        if any(kw in server for kw in cf_keywords):
            if parsed.scheme in ["http", "https"] and port in [80, 443]:
                return True
        return False
    except Exception:
        return False

def is_filtered_port(node_url: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºéœ€è¦è¿‡æ»¤çš„ç«¯å£"""
    try:
        parsed = urlparse(node_url)
        port = parsed.port or 443
        
        # éœ€è¦è¿‡æ»¤çš„ç«¯å£åˆ—è¡¨
        filtered_ports = [80, 8080, 8880, 2052, 2082, 2086, 2095, 443, 2053, 2083, 2087, 2096, 8443]
        return port in filtered_ports
    except Exception:
        return False

def filter_node_url(node_url: str) -> bool:
    """è¿‡æ»¤èŠ‚ç‚¹URLï¼Œè¿”å›Trueè¡¨ç¤ºéœ€è¦è¿‡æ»¤æ‰"""
    try:
        parsed = urlparse(node_url)
        server = parsed.hostname or ''
        
        # è¿‡æ»¤çº¯IPèŠ‚ç‚¹
        if is_ip_address(server):
            return True
            
        # è¿‡æ»¤Cloudflare http/httpsç«¯å£èŠ‚ç‚¹
        if is_cloudflare_http_node(node_url):
            return True
            
        # è¿‡æ»¤æŒ‡å®šç«¯å£çš„èŠ‚ç‚¹
        if is_filtered_port(node_url):
            return True
            
        return False
    except Exception:
        return False

def filter_nodes_from_content(content: str) -> str:
    """ä»è®¢é˜…å†…å®¹ä¸­è¿‡æ»¤èŠ‚ç‚¹"""
    if not content:
        return content
        
    try:
        lines = content.split('\n')
        filtered_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # æ£€æŸ¥æ˜¯å¦ä¸ºèŠ‚ç‚¹é“¾æ¥
            if any(line.startswith(prefix) for prefix in ['ss://', 'ssr://', 'vmess://', 'vless://', 'trojan://', 'hysteria://', 'hy://', 'hy2://']):
                # è¿‡æ»¤èŠ‚ç‚¹
                if not filter_node_url(line):
                    filtered_lines.append(line)
            else:
                # éèŠ‚ç‚¹é“¾æ¥ï¼Œä¿ç•™
                filtered_lines.append(line)
        
        return '\n'.join(filtered_lines)
            
    except Exception as e:
        logger.error(f"è¿‡æ»¤èŠ‚ç‚¹æ—¶å‡ºé”™: {e}")
        return content

# -------------------------------
# é…ç½®æ–‡ä»¶æ“ä½œ (ä¿æŒä¸å˜)
# -------------------------------
def load_yaml_config(path_yaml):
    """è¯»å– YAML é…ç½®æ–‡ä»¶ï¼Œå¦‚æ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤ç»“æ„"""
    if os.path.exists(path_yaml):
        with open(path_yaml, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    else:
        config = {
            "æœºåœºè®¢é˜…": [],
            "clashè®¢é˜…": [],
            "v2è®¢é˜…": [],
            "å¼€å¿ƒç©è€": [],
            "tgchannel": []
        }
    return config

def save_yaml_config(config, path_yaml):
    """ä¿å­˜é…ç½®åˆ° YAML æ–‡ä»¶"""
    with open(path_yaml, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True)

def get_config_channels(config_file='config.yaml'):
    """
    ä»é…ç½®æ–‡ä»¶ä¸­è·å– Telegram é¢‘é“é“¾æ¥ï¼Œ
    å°†ç±»ä¼¼ https://t.me/univstar è½¬æ¢ä¸º https://t.me/s/univstar æ ¼å¼
    """
    config = load_yaml_config(config_file)
    tgchannels = config.get('tgchannel', [])
    new_list = []
    for url in tgchannels:
        parts = url.strip().split('/')
        if parts:
            channel_id = parts[-1]
            new_list.append(f'https://t.me/s/{channel_id}')
    return new_list

# -------------------------------
# å¼‚æ­¥ HTTP è¯·æ±‚è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜)
# -------------------------------
async def fetch_content(url, session, method='GET', headers=None, timeout=15):
    """è·å–æŒ‡å®š URL çš„æ–‡æœ¬å†…å®¹"""
    try:
        async with session.request(method, url, headers=headers, timeout=timeout) as response:
            if response.status == 200:
                text = await response.text()
                return text, response.headers # è¿”å›å†…å®¹å’Œå“åº”å¤´
            else:
                logger.warning(f"URL {url} è¿”å›çŠ¶æ€ {response.status}")
                return None, None
    except Exception as e:
        logger.error(f"è¯·æ±‚ {url} å¼‚å¸¸: {e}")
        return None, None

# -------------------------------
# é¢‘é“æŠ“å–åŠè®¢é˜…æ£€æŸ¥ (ä¿æŒä¸å˜)
# -------------------------------
async def get_channel_urls(channel_url, session):
    """ä» Telegram é¢‘é“é¡µé¢æŠ“å–æ‰€æœ‰è®¢é˜…é“¾æ¥ï¼Œå¹¶è¿‡æ»¤æ— å…³é“¾æ¥"""
    content, _ = await fetch_content(channel_url, session)
    if content:
        all_urls = re.findall(RE_URL, content)
        filtered = [u for u in all_urls if "//t.me/" not in u and "cdn-telegram.org" not in u]
        logger.info(f"ä» {channel_url} æå– {len(filtered)} ä¸ªé“¾æ¥")
        return filtered
    else:
        logger.warning(f"æ— æ³•è·å– {channel_url} çš„å†…å®¹")
        return []

async def check_single_subscription(url, session):
    """
    æ£€æŸ¥å•ä¸ªè®¢é˜…é“¾æ¥çš„æœ‰æ•ˆæ€§å¹¶åˆ†ç±»ï¼š
      - åˆ¤æ–­å“åº”å¤´ä¸­çš„ subscription-userinfo ç”¨äºæœºåœºè®¢é˜…ï¼Œå¹¶æ£€æŸ¥å¯ç”¨æµé‡
      - åˆ¤æ–­å†…å®¹ä¸­æ˜¯å¦åŒ…å« 'proxies:' åˆ¤å®š clash è®¢é˜…
      - å°è¯• base64 è§£ç åˆ¤æ–­ v2 è®¢é˜…ï¼ˆè¯†åˆ« ss://ã€ssr://ã€vmess://ã€trojan://ï¼‰
    è¿”å›ä¸€ä¸ªå­—å…¸ï¼š{"url": ..., "type": ..., "info": ..., "content": ...}
    """
    headers = {'User-Agent': 'ClashforWindows/0.18.1'}
    content, response_headers = await fetch_content(url, session, headers=headers, timeout=10)

    if content is None: # å¦‚æœæ— æ³•è·å–å†…å®¹ï¼Œç›´æ¥è¿”å› None
        return None

    result = {"url": url, "type": None, "info": None, "content": content}

    # åˆ¤æ–­æœºåœºè®¢é˜…ï¼ˆæ£€æŸ¥æµé‡ä¿¡æ¯ï¼‰
    if response_headers:
        sub_info = response_headers.get('subscription-userinfo')
        if sub_info:
            nums = re.findall(r'\d+', sub_info)
            if len(nums) >= 3:
                try:
                    upload, download, total = map(int, nums[:3])
                    unused = (total - upload - download) / (1024 ** 3)
                    if unused >= MIN_GB_AVAILABLE: # è¿‡æ»¤å°‘äº5GBçš„æœºåœºè®¢é˜…
                        result["type"] = "æœºåœºè®¢é˜…"
                        result["info"] = f"å¯ç”¨æµé‡: {round(unused, 2)} GB"
                        return result
                    else:
                        logger.info(f"æœºåœºè®¢é˜… {url} å¯ç”¨æµé‡ä¸è¶³ {MIN_GB_AVAILABLE} GBï¼Œå·²æ’é™¤ã€‚")
                        return None # æ’é™¤æµé‡ä¸è¶³çš„æœºåœº
                except ValueError:
                    logger.warning(f"è§£æè®¢é˜…ä¿¡æ¯ {sub_info} å¤±è´¥ for {url}")

    # åˆ¤æ–­ clash è®¢é˜…
    if "proxies:" in content:
        try:
            # å°è¯•è§£æä¸º YAMLï¼Œè¿›ä¸€æ­¥ç¡®è®¤æ˜¯ Clash é…ç½®
            yaml.safe_load(content)
            result["type"] = "clashè®¢é˜…"
            return result
        except yaml.YAMLError:
            logger.warning(f"é“¾æ¥ {url} åŒ…å« 'proxies:' ä½†ä¸æ˜¯æœ‰æ•ˆçš„ YAML é…ç½®ï¼Œè§†ä¸ºæœªçŸ¥è®¢é˜…ã€‚")

    # åˆ¤æ–­ v2 è®¢é˜…ï¼Œé€šè¿‡ base64 è§£ç æ£€æµ‹
    try:
        # æ¸…ç†å†…å®¹ï¼Œåªä¿ç•™ Base64 å­—ç¬¦
        cleaned_content = "".join(char for char in content if char.isalnum() or char in "+/=")
        
        # é™åˆ¶å°è¯•è§£ç çš„å­—ç¬¦ä¸²é•¿åº¦ï¼Œé˜²æ­¢è¿‡å¤§æˆ–æ— æ•ˆæ•°æ®å¯¼è‡´æ€§èƒ½é—®é¢˜
        sample_for_b64 = cleaned_content[:min(len(cleaned_content), 4096)]

        # æ£€æŸ¥æ˜¯å¦ç¬¦åˆ Base64 å­—ç¬¦æ¨¡å¼
        if sample_for_b64 and re.match(r"^[A-Za-z0-9+/=]*$", sample_for_b64):
            decoded_content = base64.b64decode(sample_for_b64.encode('ascii')).decode('utf-8', errors='ignore')

            if any(proto in decoded_content for proto in ['ss://', 'ssr://', 'vmess://', 'trojan://', 'vless://', 'tuic://', 'hysteria://', 'hysteria2://']):
                result["type"] = "v2è®¢é˜…"
                try:
                    full_decoded = base64.b64decode(cleaned_content.encode('ascii')).decode('utf-8', errors='ignore')
                    result["content"] = full_decoded
                except (base64.binascii.Error, UnicodeDecodeError, ValueError) as e:
                    logger.warning(f"V2è®¢é˜… {url} çš„å®Œæ•´å†…å®¹è§£ç å¤±è´¥: {e}. å°†ä½¿ç”¨éƒ¨åˆ†å†…å®¹ã€‚")
                    result["content"] = decoded_content
                return result
        
    except (base64.binascii.Error, UnicodeDecodeError, ValueError) as e:
        logger.debug(f"Base64 è§£ç æˆ–åˆæ­¥æ£€æŸ¥å¤±è´¥ for {url}: {e}")
        pass

    result["type"] = "æœªçŸ¥è®¢é˜…"
    return result

# -------------------------------
# èŠ‚ç‚¹æœ‰æ•ˆæ€§æ£€æµ‹ï¼ˆæ ¹æ®å¤šä¸ªæ£€æµ‹å…¥å£ï¼‰ (ä¿æŒä¸å˜)
# -------------------------------
async def check_node_validity(url, target, session):
    """
    é€šè¿‡éå†å¤šä¸ªæ£€æµ‹å…¥å£æ£€æŸ¥è®¢é˜…èŠ‚ç‚¹æœ‰æ•ˆæ€§ï¼Œ
    å¦‚æœä»»ä¸€æ£€æµ‹è¿”å›çŠ¶æ€ 200ï¼Œåˆ™è®¤ä¸ºè¯¥èŠ‚ç‚¹æœ‰æ•ˆã€‚
    """
    encoded_url = quote(url, safe='')
    for check_base in CHECK_URL_LIST:
        check_url = CHECK_NODE_URL_STR.format(check_base, target, encoded_url)
        try:
            async with session.get(check_url, timeout=15) as resp:
                if resp.status == 200:
                    return url
        except Exception:
            continue
    return None

def write_url_list(url_list, file_path):
    """å°† URL åˆ—è¡¨å†™å…¥æ–‡æœ¬æ–‡ä»¶"""
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(url_list))
    logger.info(f"å·²ä¿å­˜ {len(url_list)} ä¸ªé“¾æ¥åˆ° {file_path}")

# -------------------------------
# èŠ‚ç‚¹è§£ç ä¸åˆå¹¶ (ä¼˜åŒ–éƒ¨åˆ†)
# -------------------------------
def decode_and_extract_nodes(sub_type, content):
    """
    æ ¹æ®è®¢é˜…ç±»å‹è§£ç å†…å®¹å¹¶æå–èŠ‚ç‚¹ã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«ä»£ç†é“¾æ¥çš„åˆ—è¡¨ï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰ã€‚
    """
    nodes = []
    if not content:
        return nodes

    # åº”ç”¨èŠ‚ç‚¹è¿‡æ»¤
    filtered_content = filter_nodes_from_content(content)
    if filtered_content != content:
        logger.info(f"å·²è¿‡æ»¤èŠ‚ç‚¹å†…å®¹ï¼Œç±»å‹: {sub_type}")

    # å®šä¹‰æ‰€æœ‰æ”¯æŒçš„ä»£ç†åè®®æ¨¡å¼ï¼Œæ·»åŠ  'hysteria://' å’Œ 'hysteria2://'ï¼Œå¹¶å°† 'hy://' è§†ä¸º 'hysteria://' çš„åˆ«å
    proxy_patterns = (
        r'ss://[A-Za-z0-9+/=]+',
        r'ssr://[A-Za-z0-9+/=]+',
        r'vmess://[A-Za-z0-9+/=]+',
        r'vless://[A-Za-z0-9+/=]+',
        r'trojan://[A-Za-z0-9+/=]+',
        r'hysteria://[A-Za-z0-9+/=]+',
        r'hy://[A-Za-z0-9+/=]+',
        r'hysteria2://[A-Za-z0-9+/=]+'
    )

    # ä½¿ç”¨è¿‡æ»¤åçš„å†…å®¹
    content_to_process = filtered_content

    # å¯¹äº Clash é…ç½®ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
    if sub_type == "clashè®¢é˜…" and "proxies:" in content_to_process:
        try:
            clash_config = yaml.safe_load(content_to_process)
            if clash_config and "proxies" in clash_config:
                for proxy in clash_config["proxies"]:
                    node_url = convert_clash_proxy_to_url(proxy)
                    if node_url and not filter_node_url(node_url):  # å†æ¬¡è¿‡æ»¤è½¬æ¢åçš„èŠ‚ç‚¹
                        nodes.append(node_url)
        except yaml.YAMLError as e:
            logger.warning(f"è§£æ Clash é…ç½®å¤±è´¥: {e}")
    else:
        # å¯¹äºå…¶ä»–ç±»å‹çš„è®¢é˜…ï¼Œç›´æ¥æå–ä»£ç†é“¾æ¥
        for pattern in proxy_patterns:
            found_nodes = re.findall(pattern, content_to_process, re.IGNORECASE)
            for node in found_nodes:
                if not filter_node_url(node):  # è¿‡æ»¤èŠ‚ç‚¹
                    nodes.append(node)

    return list(set(nodes))  # å»é‡

def convert_clash_proxy_to_url(proxy_dict):
    """
    å°è¯•å°† Clash ä»£ç†å­—å…¸è½¬æ¢ä¸ºæ ‡å‡†çš„ä»£ç†é“¾æ¥æ ¼å¼ã€‚
    æ”¯æŒ ss, vmess, vless, trojan, hysteria, hysteria2ï¼Œhyï¼ˆä½œä¸º hysteria çš„åˆ«åï¼‰ã€‚
    """
    ptype = proxy_dict.get('type')
    name = quote(proxy_dict.get('name', 'ClashNode'), safe='') # å¯¹åç§°è¿›è¡ŒURLç¼–ç 

    try:
        if ptype == 'ss':
            cipher = proxy_dict.get('cipher')
            password = proxy_dict.get('password')
            server = proxy_dict.get('server')
            port = proxy_dict.get('port')
            if all([cipher, password, server, port]):
                return f"ss://{base64.b64encode(f'{cipher}:{password}'.encode()).decode()}@{server}:{port}#{name}"
        
        elif ptype == 'vmess':
            vmess_config = {
                "v": proxy_dict.get('v', '2'),
                "ps": proxy_dict.get('name'),
                "add": proxy_dict.get('server'),
                "port": proxy_dict.get('port'),
                "id": proxy_dict.get('uuid'),
                "aid": proxy_dict.get('alterId', 0),
                "net": proxy_dict.get('network'),
                "type": proxy_dict.get('tls'),
                "host": proxy_dict.get('ws-opts', {}).get('headers', {}).get('Host', ''),
                "path": proxy_dict.get('ws-opts', {}).get('path', ''),
                "tls": "tls" if proxy_dict.get('tls') else ""
            }
            vmess_config = {k: v for k, v in vmess_config.items() if v not in ['', None, 0]}
            return "vmess://" + base64.b64encode(json.dumps(vmess_config, ensure_ascii=False).encode('utf-8')).decode('utf-8')

        elif ptype == 'vless':
            uuid = proxy_dict.get('uuid')
            server = proxy_dict.get('server')
            port = proxy_dict.get('port')
            params = []
            if proxy_dict.get('tls'):
                params.append('security=tls')
            if proxy_dict.get('servername'):
                params.append(f'sni={quote(proxy_dict["servername"])}')
            if proxy_dict.get('network') == 'ws':
                params.append('type=ws')
                ws_path = proxy_dict.get('ws-opts', {}).get('path', '')
                if ws_path:
                    params.append(f'path={quote(ws_path)}')
                ws_host = proxy_dict.get('ws-opts', {}).get('headers', {}).get('Host', '')
                if ws_host:
                    params.append(f'host={quote(ws_host)}')
            if proxy_dict.get('xudp'):
                params.append('xudp=true')
            if proxy_dict.get('client-fingerprint'):
                params.append(f'fp={proxy_dict["client-fingerprint"]}')
            if proxy_dict.get('flow'):
                params.append(f'flow={proxy_dict["flow"]}')
            
            param_str = "&".join(params)
            
            if all([uuid, server, port]):
                return f"vless://{uuid}@{server}:{port}?{param_str}#{name}" if param_str else f"vless://{uuid}@{server}:{port}#{name}"

        elif ptype == 'trojan':
            password = proxy_dict.get('password')
            server = proxy_dict.get('server')
            port = proxy_dict.get('port')
            params = []
            if proxy_dict.get('tls'):
                params.append('security=tls')
            if proxy_dict.get('sni'):
                params.append(f'sni={quote(proxy_dict["sni"])}')
            if proxy_dict.get('network') == 'ws':
                params.append('type=ws')
                ws_path = proxy_dict.get('ws-opts', {}).get('path', '')
                if ws_path:
                    params.append(f'path={quote(ws_path)}')
                ws_host = proxy_dict.get('ws-opts', {}).get('headers', {}).get('Host', '')
                if ws_host:
                    params.append(f'host={quote(ws_host)}')
            
            param_str = "&".join(params)

            if all([password, server, port]):
                return f"trojan://{password}@{server}:{port}?{param_str}#{name}" if param_str else f"trojan://{password}@{server}:{port}#{name}"

        elif ptype in ['hysteria', 'hy', 'hysteria2']:
            # å°† hy è§†ä¸º hysteria çš„åˆ«å
            protocol = 'hysteria2' if ptype == 'hysteria2' else 'hysteria'
            server = proxy_dict.get('server')
            port = proxy_dict.get('port')
            params = []
            if up_mbps := proxy_dict.get('up_mbps'):
                params.append(f'upmbps={up_mbps}')
            if down_mbps := proxy_dict.get('down_mbps'):
                params.append(f'downmbps={down_mbps}')
            if password := proxy_dict.get('password'):
                params.append(f'password={quote(password)}')
            if sni := proxy_dict.get('sni'):
                params.append(f'sni={quote(sni)}')
            if insecure := proxy_dict.get('insecure'):
                params.append(f'insecure={insecure}')
            if obfs := proxy_dict.get('obfs'):
                params.append(f'obfs={quote(obfs)}')
            if obfs_password := proxy_dict.get('obfs-password'):
                params.append(f'obfspassword={quote(obfs_password)}')
            
            param_str = "&".join(params)
            
            if all([server, port]):
                return f"{protocol}://{server}:{port}?{param_str}#{name}" if param_str else f"{protocol}://{server}:{port}#{name}"

    except Exception as e:
        logger.warning(f"è½¬æ¢ Clash ä»£ç† '{proxy_dict.get('name', 'æœªçŸ¥')}' åˆ° URL å¤±è´¥: {e}")
    return None

# -------------------------------
# ä¸»å‡½æ•°å…¥å£ (ä¿æŒä¸å˜)
# -------------------------------
async def main():
    config_path = 'config.yaml'
    config = load_yaml_config(config_path)

    async with aiohttp.ClientSession() as session:
        # è·å–æ‰€æœ‰ Telegram é¢‘é“ä¸­çš„ URL
        tg_channels = get_config_channels(config_path)
        all_urls_from_channels = []
        for channel in tg_channels:
            urls = await get_channel_urls(channel, session)
            all_urls_from_channels.extend(urls)
        today_urls = list(set(all_urls_from_channels)) # å»é‡
        logger.info(f"ä» Telegram é¢‘é“å…±è·å¾— {len(today_urls)} ä¸ªå»é‡é“¾æ¥")

        # å¼‚æ­¥æ£€æŸ¥æ‰€æœ‰è®¢é˜…é“¾æ¥çš„æœ‰æ•ˆæ€§å¹¶åˆ†ç±»
        tasks = [check_single_subscription(url, session) for url in today_urls]
        sub_results = []
        for coro in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc="è®¢é˜…ç­›é€‰"):
            res = await coro
            if res: # åªæ·»åŠ æœ‰æ•ˆçš„è®¢é˜…ç»“æœ
                sub_results.append(res)
        logger.info(f"å®Œæˆè®¢é˜…ç­›é€‰ï¼Œå…± {len(sub_results)} ä¸ªæœ‰æ•ˆç»“æœã€‚")

        # æ ¹æ®æ£€æŸ¥ç»“æœæŒ‰ç±»å‹åˆ†ç±»å¹¶æ›´æ–°é…ç½®
        subs = []  # æœºåœºè®¢é˜…
        clash = [] # Clash è®¢é˜…
        v2 = []    # V2ray/SSR/SS è®¢é˜…
        play = []  # å¼€å¿ƒç©è€ï¼ˆå«æµé‡ä¿¡æ¯ï¼‰
        all_decoded_nodes = set() # ç”¨äºå­˜å‚¨æ‰€æœ‰å»é‡åçš„è§£ç èŠ‚ç‚¹

        for res in sub_results:
            if res["type"] == "æœºåœºè®¢é˜…":
                subs.append(res["url"])
                if res["info"]:
                    play.append(f'{res["info"]} {res["url"]}')
            elif res["type"] == "clashè®¢é˜…":
                clash.append(res["url"])
            elif res["type"] == "v2è®¢é˜…":
                v2.append(res["url"])
            # å…¶ä»–ç±»å‹ï¼ˆå¦‚"æœªçŸ¥è®¢é˜…"ï¼‰ä¹Ÿä¼šè¢«å¤„ç†ä»¥å°è¯•æå–èŠ‚ç‚¹

            # å°è¯•è§£ç å¹¶æå–èŠ‚ç‚¹ï¼ŒåŠ å…¥åˆ°æ€»çš„èŠ‚ç‚¹é›†åˆä¸­
            nodes = decode_and_extract_nodes(res["type"], res["content"])
            all_decoded_nodes.update(nodes)

        print("\n--- è®¢é˜…åˆ†ç±»ç»“æœ ---")
        print(f"æœºåœºè®¢é˜…æ•°é‡ (å¯ç”¨æµé‡ >= {MIN_GB_AVAILABLE}GB): {len(subs)}")
        print(f"Clash è®¢é˜…æ•°é‡: {len(clash)}")
        print(f"V2ray/SSR/SS è®¢é˜…æ•°é‡: {len(v2)}")
        print(f"å¼€å¿ƒç©è€ (å«æµé‡ä¿¡æ¯) æ•°é‡: {len(play)}")

        # åˆå¹¶å¹¶æ›´æ–°é…ç½®ï¼ˆä¸åŸæœ‰æ•°æ®åˆå¹¶ï¼‰
        config["æœºåœºè®¢é˜…"] = sorted(list(set(config.get("æœºåœºè®¢é˜…", []) + subs)))
        config["clashè®¢é˜…"] = sorted(list(set(config.get("clashè®¢é˜…", []) + clash)))
        config["v2è®¢é˜…"] = sorted(list(set(config.get("v2è®¢é˜…", []) + v2)))
        config["å¼€å¿ƒç©è€"] = sorted(list(set(config.get("å¼€å¿ƒç©è€", []) + play)))
        save_yaml_config(config, config_path)
        logger.info("é…ç½®æ–‡ä»¶å·²æ›´æ–°ã€‚")

        # å†™å…¥è®¢é˜…å­˜å‚¨æ–‡ä»¶ï¼ˆåŒ…å«æµé‡ä¿¡æ¯å’Œæœºåœºè®¢é˜…é“¾æ¥ï¼‰
        sub_store_file = config_path.replace('.yaml', '_sub_store.txt')
        content_to_write = "-- play_list --\n\n" + "\n".join(play) + "\n\n-- sub_list --\n\n" + "\n".join(subs)
        with open(sub_store_file, 'w', encoding='utf-8') as f:
            f.write(content_to_write)
        logger.info(f"è®¢é˜…å­˜å‚¨æ–‡ä»¶å·²ä¿å­˜è‡³ {sub_store_file}")

        # å†™å…¥æ‰€æœ‰è§£ç åçš„èŠ‚ç‚¹
        all_nodes_file = config_path.replace('.yaml', '_all_merged_nodes.txt')
        write_url_list(sorted(list(all_decoded_nodes)), all_nodes_file)
        logger.info(f"æ‰€æœ‰è§£ç å¹¶åˆå¹¶åçš„èŠ‚ç‚¹å·²ä¿å­˜è‡³ {all_nodes_file}ï¼Œå…± {len(all_decoded_nodes)} ä¸ªèŠ‚ç‚¹ã€‚")

        # è¾“å‡ºè¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯
        print("\n--- èŠ‚ç‚¹è¿‡æ»¤ç»Ÿè®¡ ---")
        print(f"âœ… è¿‡æ»¤åçš„æœ‰æ•ˆèŠ‚ç‚¹æ•°é‡: {len(all_decoded_nodes)}")
        print("ğŸ” è¿‡æ»¤è§„åˆ™:")
        print("   - çº¯IPèŠ‚ç‚¹ (IPv4/IPv6)")
        print("   - Cloudflare http/httpsç«¯å£èŠ‚ç‚¹")
        print("   - æŒ‡å®šç«¯å£èŠ‚ç‚¹ (80, 8080, 8880, 2052, 2082, 2086, 2095, 443, 2053, 2083, 2087, 2096, 8443)")
        print("âœ… åªä¿ç•™é«˜è´¨é‡åŸŸåèŠ‚ç‚¹")

        # æ‰¹é‡æ£€æµ‹å„ç±»è®¢é˜…çš„èŠ‚ç‚¹æœ‰æ•ˆæ€§å¹¶å†™å…¥æ–‡ä»¶ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼Œå› ä¸ºè¿™é‡Œçš„"èŠ‚ç‚¹"æ˜¯è®¢é˜…é“¾æ¥æœ¬èº«ï¼‰
        subscription_targets = {
            "æœºåœºè®¢é˜…": {"urls": subs, "target": "loon", "file_suffix": "_loon.txt"},
            "clashè®¢é˜…": {"urls": clash, "target": "clash", "file_suffix": "_clash.txt"},
            "v2è®¢é˜…": {"urls": v2, "target": "v2ray", "file_suffix": "_v2.txt"}
        }

        for sub_type, data in subscription_targets.items():
            if data["urls"]:
                logger.info(f"å¼€å§‹æ£€æµ‹ '{sub_type}' ç±»å‹çš„è®¢é˜…é“¾æ¥æœ‰æ•ˆæ€§...")
                tasks = [check_node_validity(url, data["target"], session) for url in data["urls"]]
                valid_urls_for_type = []
                for coro in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=f"{sub_type} é“¾æ¥æ£€æµ‹"):
                    res = await coro
                    if res:
                        valid_urls_for_type.append(res)
                valid_file = config_path.replace('.yaml', data["file_suffix"])
                write_url_list(valid_urls_for_type, valid_file)
            else:
                logger.info(f"æ²¡æœ‰ '{sub_type}' ç±»å‹çš„é“¾æ¥éœ€è¦æ£€æµ‹ã€‚")


if __name__ == '__main__':
    asyncio.run(main())
